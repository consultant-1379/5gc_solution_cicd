parameters:
  ################################### Network variables #######################
  timezone: CET
  ntp_server_ips: [10.221.17.6]
  dns_server_ips: [10.221.16.10]
  os_endpoint_ips: [10.221.12.201, 10.155.142.68,10.221.12.203]
  director_external_network: eccd1-ccd-oam
  director_external_subnet: eccd1-ccd-oam_subnet
  security_groups_enabled: False
  # The list of remote CIDRs allowed to SSH to directors when SG are enabled
  #director_ssh_allowed_cidrs: [<fill>]
  # VRRP traffic might need to be specifically enabled when security groups are
  # enabled on deployments running Openstack older than Pike release
  #allow_vrrp_address_by_mac: False
  #receive_packet_steering: false

  ### Ingress/egress via LB ###################################################
  lb_enabled: False
  lb_external_network: <fill>
  lb_external_subnet: <fill>
  # lb_external_security_groups: [<fill>]

  ##################################### L4LB variables ########################

  lb_image: node-image
  lb_flavor: m1.medium

  lb_root_volume_size: 20

  ################################### Master variables ########################
  master_image: eccd-2.26.0-node-image
  master_flavor: MGMT_8vcpu_16384MBmem_0GBdisk
  masters_count: 3

  master_root_volume_size: 50
  master_config_volume_size: 15

  # managed-on-host, ha-offline, unmanaged
  master_metadata:
    ha-policy: ha-offline

  ################################### Director variables ######################
  director_image: eccd-2.26.0-director-image
  director_flavor: MGMT_2vcpu_8192MBmem_0GBdisk
  directors_count: 2

  director_root_volume_size: 30
  director_config_volume_size: 24

  director_virtual_router_id: 50
  director_external_vip: 10.117.60.6

  # managed-on-host, ha-offline, unmanaged
  director_metadata:
    ha-policy: ha-offline

  ################################## Licensing variables ######################
  ccd_licensing_domains:
  - productType: ECCD
    swltId: STA-CCD-1
    customerId: 946060
  ccd_licensing_nels_host: nelsaas-vnf1-thrift.sero.gic.ericsson.se

  ################################## Ansible variables ######################
  ansible_variables:
    openstack_auth_url: https://os-ext-vip-n84vpod1-cee.sc.sero.gic.ericsson.se:5000
    infra_node_pool_name: pool1
    kube_manager_kube_api_burst: 100
    kube_manager_kube_api_qps: 100
    kube_manager_attach_detach_reconcile_sync_period: 5m0s
    kube_manager_disable_attach_detach_reconcile_sync: True
    openstack_username: admin
    openstack_user_password: sSnuxRMhKLc3QqlFVZTsEuBlkSOA85lD9NSFIjaO
    openstack_project_name: admin
    openstack_domain_name: Default
    openstack_region: CEERegion
    ecfe_enabled: true
    ingressctrl_service_annotations: 'metallb.universe.tf/address-pool: system-pool'
    ecfe_config_map_raw:
      bgp-bfd-peers:
      - peer-address: 11.3.2.254
        peer-asn: 8002
        my-asn: 7002
        hold-time: 180s
        min-rx: 300ms
        min-tx: 300ms
        multiplier: 3
        my-address-pools:
        - pcc-smf-nsmf
        - pcc-smf-notification
        - ccdm-5g-traffic
        - ccsm-ausf-5g-sig
        - ccrc-nrf-sig
        - ccsm-udm-5g-sig
        - pcc-amf-namf
        - ccrc-nssf-sig
        - sc-bsf-sig
        - sc-bsf-dia-sig
        - ccsm-hss-dia-sig
        - ccsm-eir-5g-sig
        - ccsm-hss-epc-http-sig
        - sc-scp-sig
        - cces-5g-sbi-traffic
        - cces-5g-nbi-trust-traffic
      - peer-address: 214.14.171.254
        peer-asn: 8010
        my-asn: 7010
        hold-time: 180s
        min-rx: 300ms
        min-tx: 300ms
        multiplier: 3
        my-address-pools:
        - system-pool
        - pcc-oam
        - pcg-oam
        - ccdm-oam
        - ccdm-5g-prov
        - ccdm-4g-prov
        - ccsm-oam
        - ccrc-oam
        - eda-oam
        - sc-oam
        - cces-oam
        - cces-5g-prov
        node-selectors:
        - match-labels:
            type: standard
      - peer-address: 11.1.18.254
        peer-asn: 8018
        my-asn: 7018
        hold-time: 180s
        min-rx: 300ms
        min-tx: 300ms
        multiplier: 3
        my-address-pools:
        - ccdm-intersite
        - ccdm-4g-traffic
      address-pools:
      - name: pcc-smf-nsmf
        protocol: bgp
        addresses:
        - 5.8.6.1/32
        auto-assign: false
      - name: pcc-smf-notification
        protocol: bgp
        addresses:
        - 5.8.6.2/32
        auto-assign: false
      - name: ccdm-5g-traffic
        protocol: bgp
        addresses:
        - 5.8.6.4/32
        auto-assign: false
      - name: ccsm-ausf-5g-sig
        protocol: bgp
        addresses:
        - 5.8.6.5/32
        auto-assign: false
      - name: ccrc-nrf-sig
        protocol: bgp
        addresses:
        - 5.8.6.6/32
        auto-assign: false
      - name: ccsm-udm-5g-sig
        protocol: bgp
        addresses:
        - 5.8.6.7/32
        auto-assign: false
      - name: pcc-amf-namf
        protocol: bgp
        addresses:
        - 5.8.6.9/32
        auto-assign: false
      - name: ccrc-nssf-sig
        protocol: bgp
        addresses:
        - 5.8.6.10/32
        auto-assign: false
      - name: sc-bsf-sig
        protocol: bgp
        addresses:
        - 5.8.6.11/32
        auto-assign: false
      - name: sc-bsf-dia-sig
        protocol: bgp
        addresses:
        - 5.8.6.12/32
        auto-assign: false
      - name: ccsm-hss-dia-sig
        protocol: bgp
        addresses:
        - 5.8.6.13/32
        auto-assign: false
      - name: ccsm-eir-5g-sig
        protocol: bgp
        addresses:
        - 5.8.6.14/32
        auto-assign: false
      - name: ccsm-hss-epc-http-sig
        protocol: bgp
        addresses:
        - 5.8.6.3/32
        auto-assign: false
      - name: sc-scp-sig
        protocol: bgp
        addresses:
        - 5.8.6.35/32
        auto-assign: false
      - name: cces-5g-sbi-traffic
        protocol: bgp
        addresses:
        - 5.8.6.8/32
        auto-assign: false
      - name: cces-5g-nbi-trust-traffic
        protocol: bgp
        addresses:
        - 5.8.6.36/32
        auto-assign: false
      - name: cces-oam
        protocol: bgp
        addresses:
        - 214.14.170.110/32
        auto-assign: false
      - name: cces-5g-prov
        protocol: bgp
        addresses:
        - 214.14.170.111/32
        auto-assign: false
      - name: system-pool
        protocol: bgp
        addresses:
        - 214.14.170.121/32
        auto-assign: false
      - name: pcc-oam
        protocol: bgp
        addresses:
        - 214.14.170.102/32
        auto-assign: false
      - name: pcg-oam
        protocol: bgp
        addresses:
        - 214.14.170.97/32
        auto-assign: false
      - name: ccdm-oam
        protocol: bgp
        addresses:
        - 214.14.170.98/32
        auto-assign: false
      - name: ccdm-5g-prov
        protocol: bgp
        addresses:
        - 214.14.170.99/32
        auto-assign: false
      - name: ccdm-4g-prov
        protocol: bgp
        addresses:
        - 214.14.170.109/32
        auto-assign: false
      - name: ccsm-oam
        protocol: bgp
        addresses:
        - 214.14.170.100/32
        auto-assign: false
      - name: ccrc-oam
        protocol: bgp
        addresses:
        - 214.14.170.101/32
        auto-assign: false
      - name: eda-oam
        protocol: bgp
        addresses:
        - 214.14.170.103/32
        auto-assign: false
      - name: sc-oam
        protocol: bgp
        addresses:
        - 214.14.170.112/32
        auto-assign: false
      - name: ccdm-intersite
        protocol: bgp
        addresses:
        - 5.8.6.33/32
        auto-assign: false
      - name: ccdm-4g-traffic
        protocol: bgp
        addresses:
        - 5.8.6.34/32
        auto-assign: false
    kube_network_extra_plugin: multus
    ipv4pool_ipip_mode: "Off"
    openstack_node_volume_attach_limit: 20
    kube_api_ingress_host: kubeapi.ingress.n84-eccd1.sero.gic.ericsson.se
    container_registry_hostname: container-registry.ingress.n84-eccd1.sero.gic.ericsson.se
    container_registry_custom_pw: c0ntainerReg!stry
    prometheus_webhook_snmp_enabled: True
    snmp_trap_receiver_host: 10.155.146.237

    # Victoria resources parameters
    pm_vmstorage_retention_time: 30d
    pm_vmstorage_volume_size: 200Gi
    pm_vmagent_memory_limit: 700Mi
    pm_vmagent_maxscrape_size: 128MB
    pm_vmselect_cpu_limit: 2
    pm_vmselect_cpu_requests: 500m
    pm_vmselect_memory_limit: 4Gi
    pm_vmstorage_memory_limit: 7Gi

    # Other monitor component parameters
    pm_server_nodeExporter_default_collectors_disabled: false

    # Some NFs include a requirement on CoreDNS cache TTL
    kube_dns_success_ttl: 5
    kube_dns_denial_ttl: 5
    nodelocalDNS_config_map_fwdzones:
    - domain: 3gppnetwork.org
      dns_server: 11.0.18.1

    # The following ansible variables can be used to configure the licensing application
    ccd_app_sys_info_nels_host_ip: 10.155.142.68 #The IP address of Application Info Collection Service in the NeLS
    ccd_app_sys_info_nels_host_name: nelsaasvnf1.nels.ericsson.com #valid hostname of Application Info Collection Service

    sriov_network_device_plugin_enabled: true
    sriov_network_device_plugin_configs:
      pool2:
        node_selectors: >
          { "node-pool": "pool2" }
        sriov_network_device_plugin_configmap_name: "sriov-dp-configmap2"
        sriov_network_device_plugin_configmap_data: >
          {
              "resourceList": [{
                      "resourceName": "intel_sriov_dpdk_left",
                      "selectors": {
                          "pciAddresses": ["0000:00:06.0", "0000:00:08.0", "0000:00:0a.0", "0000:00:0c.0"],
                          "drivers": ["vfio-pci", "igb_uio"]
                      }
                  },
                  {
                      "resourceName": "intel_sriov_dpdk_right",
                      "selectors": {
                          "pciAddresses": ["0000:00:07.0", "0000:00:09.0", "0000:00:0b.0", "0000:00:0d.0"],
                          "drivers": ["vfio-pci", "igb_uio"]
                      }
                  }
              ]
          }

      pool3:
        node_selectors: >
          { "node-pool": "pool3" }
        sriov_network_device_plugin_configmap_name: "sriov-dp-configmap3"
        sriov_network_device_plugin_configmap_data: >
          {
              "resourceList": [{
                      "resourceName": "dp_sriov_mlx5_left",
                      "selectors": {
                          "pciAddresses": ["0000:00:06.0", "0000:00:08.0", "0000:00:0a.0", "0000:00:0c.0"],
                          "vendors": ["15b3"],
                          "drivers": ["mlx5_core"],
                          "isRdma": true
                      }
                  },
                  {
                      "resourceName": "dp_sriov_mlx5_right",
                      "selectors": {
                          "pciAddresses": ["0000:00:07.0", "0000:00:09.0", "0000:00:0b.0", "0000:00:0d.0"],
                          "vendors": ["15b3"],
                          "drivers": ["mlx5_core"],
                          "isRdma": true
                      }
                  }
              ]
          }


  ################################### Worker variables ########################

  node_pools:
  - name: pool1
    image: eccd-2.26.0-node-image
    flavor: STD_72vcpu_327680MBmem_0GBdisk
    count: 20
    root_volume_size: 180
    # managed-on-host, ha-offline, unmanaged
    metadata:
      ha-policy: ha-offline

    # try max_pods parameter in this DMC 1.7
    max_pods: 150

    cpu_manager_policy: "none"
    reserved_cpus: ""
    isolate_interrupts: false

    use_trunks: true
    external_networks:

    # standard worker eth1
    - network: eccd1-ecfe-signaling
      subnet: eccd1-ecfe-signaling_subnet
      port_extra_properties:
        port_security_enabled: false

    # standard worker eth2
    - network: eccd1-ecfe-oam
      subnet: eccd1-ecfe-oam_subnet
      port_extra_properties:
        port_security_enabled: false

    # standard worker eth3
    - network: eccd1-ecfe-intersite
      subnet: eccd1-ecfe-intersite_subnet
      port_extra_properties:
        port_security_enabled: false

    # standard worker eth4
    - network: eccd1-macvlan-parent-1
      subnet: eccd1-macvlan-parent-1_subnet
      port_extra_properties:
        port_security_enabled: false


    labels: "type=standard"
    node_role: "worker"
    server_group_policies: ['anti-affinity']
    nova_availability_zone: nova
    cinder_availability_zone: nova
    pre_join_user_script: |
      #!/usr/bin/env bash
      set -ue

      mv /lib/modules/$(uname -r)/kernel/net/sctp/sctp.ko.zst /home/eccd/

      cat << EOF > apparmor-docker-pcc
      #include <tunables/global>

      profile docker-pcc flags=(attach_disconnected,mediate_deleted) {
        #include <abstractions/base>
        network,
        capability,
        file,
        mount,
        umount,
        ptrace peer=@{profile_name},
      }
      EOF

      mv apparmor-docker-pcc /etc/apparmor.d/
      systemctl restart apparmor

      function load_kernel_module() {
        for m in $@; do
          modprobe $m && echo $m >> /etc/modules-load.d/dm5gc_nfvi_preload.conf
        done
      }
      load_kernel_module ip6table_mangle fou

      # adjust kernel parameters for DM 5GC CNFs
      cat << EOF >> /etc/sysctl.conf
      ## update to kernel parameters required by Search Engine
      vm.max_map_count = 262144
      EOF
      sysctl -p

      # Label the worker nodes for PCC
      cfn="/var/lib/os-collect-config/cfn.json"
      node_index=$(jq -r '.deployments[0].inputs[] | select(.name=="node_index") | .value' ${cfn})
      if [[ "${node_index}" == "0" ]] || [[ "${node_index}" == "1" ]]; then
          label="pcc-mm-pod=controller,pcc-sm-pod=non-controller,"
      elif [[ "${node_index}" == "2" ]] || [[ "${node_index}" == "3" ]]; then
          label="pcc-sm-pod=controller,pcc-mm-pod=non-controller,"
      else
          label="pcc-mm-pod=non-controller,pcc-sm-pod=non-controller,"
      fi
      sed -i "s/node-labels=/node-labels=${label}/g" /usr/local/lib/systemd/system/kubelet.service
      # Set VirtIO vNIC queues
      cat <<EOF > /usr/local/bin/set_virtio_eth_queue.sh
      if [[ \$# -ne 1 ]]; then
          echo "Error: wrong argument. Example: \$0 4"
          exit 1
      fi
      new_queue=\$1
      virtio_eth_list=\$(ls -l /sys/class/net | grep virtio | awk '{print \$9}')
      for virtio_eth in \${virtio_eth_list}; do
          echo -n "Set \${virtio_eth} to \${new_queue} queues ... "
          max_queue=\$(ethtool -l \${virtio_eth} | grep Combined | awk '{print \$2}' | head -1)
          if [[ \${max_queue} -ge \${new_queue} ]]; then
              ethtool -L \${virtio_eth} combined \${new_queue} && echo "OK"
          else
            echo "SKIP: exceeding max \${max_queue} queues"
          fi
      done
      EOF
      chmod a+x /usr/local/bin/set_virtio_eth_queue.sh
      QUEUES=4
      cat <<EOF > /etc/systemd/system/set_virtio_eth_queue.service
      [Unit]
      Description=Set queue number for virtio NIC when multi-queue is enabled
      [Service]
      Type=oneshot
      ExecStart=/bin/bash -c "/usr/local/bin/set_virtio_eth_queue.sh ${QUEUES}"
      [Install]
      WantedBy=multi-user.target
      EOF
      systemctl enable set_virtio_eth_queue.service
      systemctl start set_virtio_eth_queue.service

    #post_join_user_script: ""

  # HT worker pool with Intel SR-IOV VFs
  - name: pool2
    image: eccd-2.26.0-node-image
    flavor: HT_46vcpu_81920MBmem_0GBdisk
    count: 0
    root_volume_size: 30
    # managed-on-host, ha-offline, unmanaged
    metadata:
      ha-policy: managed-on-host

    external_networks:

    # HT worker eth1
    - network: eccd1-ecfe-oam
      subnet: eccd1-ecfe-oam_subnet
      port_extra_properties:
        port_security_enabled: false

    # HT worker eth2
    - network: sriov-flat-left
      subnet: sriov-flat-left_subnet
      port_extra_properties:
        port_security_enabled: false
        binding:vnic_type: direct

    # HT worker eth3
    - network: sriov-flat-right
      subnet: sriov-flat-right_subnet
      port_extra_properties:
        port_security_enabled: false
        binding:vnic_type: direct

    # HT worker eth4
    - network: sriov-flat-left
      subnet: sriov-flat-left_subnet
      port_extra_properties:
        port_security_enabled: false
        binding:vnic_type: direct

    # HT worker eth5
    - network: sriov-flat-right
      subnet: sriov-flat-right_subnet
      port_extra_properties:
        port_security_enabled: false
        binding:vnic_type: direct

    # HT worker eth6
    - network: sriov-flat-left
      subnet: sriov-flat-left_subnet
      port_extra_properties:
        port_security_enabled: false
        binding:vnic_type: direct

    # HT worker eth7
    - network: sriov-flat-right
      subnet: sriov-flat-right_subnet
      port_extra_properties:
        port_security_enabled: false
        binding:vnic_type: direct

    # HT worker eth8
    - network: sriov-flat-left
      subnet: sriov-flat-left_subnet
      port_extra_properties:
        port_security_enabled: false
        binding:vnic_type: direct

    # HT worker eth9
    - network: sriov-flat-right
      subnet: sriov-flat-right_subnet
      port_extra_properties:
        port_security_enabled: false
        binding:vnic_type: direct

    labels: "type=high-throughput nic_vendor=intel"
    node_role: "worker"
    server_group_policies: ['soft-anti-affinity']
    nova_availability_zone: nova
    cinder_availability_zone: nova

    hugepage_type: 1GB
    hugepage_number_1gb: 4
    cpu_manager_policy: static
    # Only cpu '0' reserved prior to CCD2.18, however it needs more cpus to be reserved from CCD2.18
    # Set reserved_cpus to 0-1 as a part of isolated configuration in CCD 2.21
    reserved_cpus: "0-1"
    isolate_interrupts: true

    pre_join_user_script: |
      #!/usr/bin/env bash
      set -ue
      # Taint HT workers
      sed -i "s/KUBELET_EXTRA_ARGS=/&--register-with-taints=high-throughput=true:NoSchedule /" /usr/local/lib/systemd/system/kubelet.service

      # Bind SR-IOV VF to DPDK driver
      ifdown eth2
      ifdown eth3
      ifdown eth4
      ifdown eth5
      ifdown eth6
      ifdown eth7
      ifdown eth8
      ifdown eth9
      driverctl set-override 0000:00:06.0 igb_uio
      driverctl set-override 0000:00:07.0 igb_uio
      driverctl set-override 0000:00:08.0 igb_uio
      driverctl set-override 0000:00:09.0 igb_uio
      driverctl set-override 0000:00:0a.0 igb_uio
      driverctl set-override 0000:00:0b.0 igb_uio
      driverctl set-override 0000:00:0c.0 igb_uio
      driverctl set-override 0000:00:0d.0 igb_uio
      # Set VirtIO vNIC queues
      cat <<EOF > /usr/local/bin/set_virtio_eth_queue.sh
      if [[ \$# -ne 1 ]]; then
          echo "Error: wrong argument. Example: \$0 4"
          exit 1
      fi
      new_queue=\$1
      virtio_eth_list=\$(ls -l /sys/class/net | grep virtio | awk '{print \$9}')
      for virtio_eth in \${virtio_eth_list}; do
          echo -n "Set \${virtio_eth} to \${new_queue} queues ... "
          max_queue=\$(ethtool -l \${virtio_eth} | grep Combined | awk '{print \$2}' | head -1)
          if [[ \${max_queue} -ge \${new_queue} ]]; then
              ethtool -L \${virtio_eth} combined \${new_queue} && echo "OK"
          else
            echo "SKIP: exceeding max \${max_queue} queues"
          fi
      done
      EOF
      chmod a+x /usr/local/bin/set_virtio_eth_queue.sh
      QUEUES=4
      cat <<EOF > /etc/systemd/system/set_virtio_eth_queue.service
      [Unit]
      Description=Set queue number for virtio NIC when multi-queue is enabled
      [Service]
      Type=oneshot
      ExecStart=/bin/bash -c "/usr/local/bin/set_virtio_eth_queue.sh ${QUEUES}"
      [Install]
      WantedBy=multi-user.target
      EOF
      systemctl enable set_virtio_eth_queue.service
      systemctl start set_virtio_eth_queue.service

  # HT worker pool with Mellanox SR-IOV VFs
  - name: pool3
    image: eccd-2.26.0-node-image
    flavor: HT_46vcpu_81920MBmem_0GBdisk
    count: 6
    root_volume_size: 30
    # managed-on-host, ha-offline, unmanaged
    metadata:
      ha-policy: managed-on-host

    external_networks:

    # HT worker eth1
    - network: eccd1-ecfe-oam
      subnet: eccd1-ecfe-oam_subnet
      port_extra_properties:
        port_security_enabled: false

    # HT worker eth2
    - network: sriov-flat-left
      subnet: sriov-flat-left_subnet
      port_extra_properties:
        port_security_enabled: false
        binding:vnic_type: direct
        value_specs:
          binding:profile: {trusted: "True"}

    # HT worker eth3
    - network: sriov-flat-right
      subnet: sriov-flat-right_subnet
      port_extra_properties:
        port_security_enabled: false
        binding:vnic_type: direct
        value_specs:
          binding:profile: {trusted: "True"}

    # HT worker eth4
    - network: sriov-flat-left
      subnet: sriov-flat-left_subnet
      port_extra_properties:
        port_security_enabled: false
        binding:vnic_type: direct
        value_specs:
          binding:profile: {trusted: "True"}

    # HT worker eth5
    - network: sriov-flat-right
      subnet: sriov-flat-right_subnet
      port_extra_properties:
        port_security_enabled: false
        binding:vnic_type: direct
        value_specs:
          binding:profile: {trusted: "True"}

    # HT worker eth6
    - network: sriov-flat-left
      subnet: sriov-flat-left_subnet
      port_extra_properties:
        port_security_enabled: false
        binding:vnic_type: direct
        value_specs:
          binding:profile: {trusted: "True"}

    # HT worker eth7
    - network: sriov-flat-right
      subnet: sriov-flat-right_subnet
      port_extra_properties:
        port_security_enabled: false
        binding:vnic_type: direct
        value_specs:
          binding:profile: {trusted: "True"}

    # HT worker eth8
    - network: sriov-flat-left
      subnet: sriov-flat-left_subnet
      port_extra_properties:
        port_security_enabled: false
        binding:vnic_type: direct
        value_specs:
          binding:profile: {trusted: "True"}

    # HT worker eth9
    - network: sriov-flat-right
      subnet: sriov-flat-right_subnet
      port_extra_properties:
        port_security_enabled: false
        binding:vnic_type: direct
        value_specs:
          binding:profile: {trusted: "True"}

    labels: "type=high-throughput nic_vendor=mellanox"
    node_role: "worker"
    server_group_policies: ['soft-anti-affinity']
    nova_availability_zone: nova
    cinder_availability_zone: nova

    hugepage_type: 1GB
    hugepage_number_1gb: 4
    cpu_manager_policy: static
    # Only cpu '0' reserved prior to CCD2.18, however it needs more cpus to be reserved from CCD2.18
    # Set reserved_cpus to 0-1 as a part of isolated configuration in CCD 2.21
    reserved_cpus: "0-1"
    isolate_interrupts: true

    pre_join_user_script: |
      #!/usr/bin/env bash
      set -ue
      # Taint HT workers
      sed -i "s/KUBELET_EXTRA_ARGS=/&--register-with-taints=high-throughput=true:NoSchedule /" /usr/local/lib/systemd/system/kubelet.service
      # Set VirtIO vNIC queues
      cat <<EOF > /usr/local/bin/set_virtio_eth_queue.sh
      if [[ \$# -ne 1 ]]; then
          echo "Error: wrong argument. Example: \$0 4"
          exit 1
      fi
      new_queue=\$1
      virtio_eth_list=\$(ls -l /sys/class/net | grep virtio | awk '{print \$9}')
      for virtio_eth in \${virtio_eth_list}; do
          echo -n "Set \${virtio_eth} to \${new_queue} queues ... "
          max_queue=\$(ethtool -l \${virtio_eth} | grep Combined | awk '{print \$2}' | head -1)
          if [[ \${max_queue} -ge \${new_queue} ]]; then
              ethtool -L \${virtio_eth} combined \${new_queue} && echo "OK"
          else
            echo "SKIP: exceeding max \${max_queue} queues"
          fi
      done
      EOF
      chmod a+x /usr/local/bin/set_virtio_eth_queue.sh
      QUEUES=4
      cat <<EOF > /etc/systemd/system/set_virtio_eth_queue.service
      [Unit]
      Description=Set queue number for virtio NIC when multi-queue is enabled
      [Service]
      Type=oneshot
      ExecStart=/bin/bash -c "/usr/local/bin/set_virtio_eth_queue.sh ${QUEUES}"
      [Install]
      WantedBy=multi-user.target
      EOF
      systemctl enable set_virtio_eth_queue.service
      systemctl start set_virtio_eth_queue.service

    

  subport_data:
    pool1:
      subportsets:
        subportset1:
        - network_id: 17dc55f3-e4de-499c-9272-6925c89b485c
          vlan_id: 3023
        - network_id: be5588a4-4e17-4fea-859b-3e77eb52b81e
          vlan_id: 3829
        - network_id: bef7c364-9c70-4328-a7d3-ee2d070a6ae4
          vlan_id: 3879
        - network_id: 56f1ab74-65d2-446f-a6c0-0e24ca50d9b7
          vlan_id: 3877
        - network_id: 4f28d5b4-491e-49e7-9309-f3ca7576b89a
          vlan_id: 3702
        - network_id: 63aa7de4-1bb7-4c39-8b3a-29730e833997
          vlan_id: 3826
        - network_id: 000a5167-c125-46f5-a611-449477145ede
          vlan_id: 3852
        - network_id: 1fba2d1a-ac6a-4f1a-b8b8-9f83b894d1b2
          vlan_id: 3876
        - network_id: 4a279775-d723-4472-94be-737c2dbdb453
          vlan_id: 3400
        - network_id: b83e5795-3098-47a2-baec-514aba1df434
          vlan_id: 3954
        - network_id: f1640040-4629-43ce-87f9-f58b4a5cb62a
          vlan_id: 3827
        - network_id: 932c3fe2-862e-4aaa-bb8b-0a8a51037350
          vlan_id: 3701
        - network_id: edf4d080-80af-4b29-99cf-999ace20a78c
          vlan_id: 3830
      nicsets:
        3:
        - subportset1

  ################################### Logger variables ########################
  logger_enabled: False

  ################################### Other variables #########################
  nova_availability_zone: nova
  master_server_group_policies: ['anti-affinity']
  director_server_group_policies: ['anti-affinity']
  cinder_availability_zone: nova

  os_cacert: |
    -----BEGIN CERTIFICATE-----
    MIIFgjCCA2qgAwIBAgIQXfAZDd+9XJpFa1GJ2eqreDANBgkqhkiG9w0BAQsFADAV
    MRMwEQYDVQQDEwpFR0FEUm9vdENBMB4XDTE4MDIwOTE1MzMyM1oXDTM4MDIwOTE1
    NDAwMlowFTETMBEGA1UEAxMKRUdBRFJvb3RDQTCCAiIwDQYJKoZIhvcNAQEBBQAD
    ggIPADCCAgoCggIBAM5hqGswhA9sZstmTwCCp18z7Y+OSUGzFSrJ/ocI4h9UsusA
    40yOvmt4XnNxb6oGFsEOE+8eHzaCE00TlwS9nLGq6x+cj8nDuLYI66KEimR1xdkt
    3mwJbSZ/4tuulgvyUcARB+xcRSsyLWraboxFa41VY6yCeBfs4FKyrkmGmhFxzknN
    jKQQRkfRQz3wyggWebSa1Aa2DZdMa0BSn+ZnFcMyhOamLxj5RVvTLwuoqhSCfVU5
    QW5ioLQ85DFg4667VClP+gDQ0F2XoLBmUPDmSXrlHZ3x+yA+ls0rdh79N84dq9hU
    2Y3zApqyohjeFCj9F0DiGMRwQ8cj9PhMHp9mCreuS6ZMXk5Phqil5gyyf1Blqg9Y
    21JWUoag+CKFlTbL6yRRauhbLCFTxZxpc6noG0B5fXTEftIl040jQ0XFcx6BOBru
    DESkdhCuT4LZw4tOU79v5OVxLAcZOWsC+l/gt2gRRToz3HFFR4R7vDzVJKom5d22
    dwy7v17kVcIsbMNndJMELz8UXK7tbHioBNnW8Sp7sRFrxz/lPzUF6eJFucgrpnng
    n8xBoiBbZOWu7EFttTOE2pKpPPGFbl+c0EbyUa71RxidRsBKjy3aTDwT967q1h/v
    uZDecSQH3JDPqH66MvP31YvLOLxSczWYYLC0+R23SslEgRFOxmtF4YODM4KPAgMB
    AAGjgc0wgcowCwYDVR0PBAQDAgGGMA8GA1UdEwEB/wQFMAMBAf8wHQYDVR0OBBYE
    FFZFQloUqLksRP6bNcTb7i85gk3QMBAGCSsGAQQBgjcVAQQDAgEAMHkGA1UdIARy
    MHAwbgYEVR0gADBmMGQGCCsGAQUFBwICMFgeVgBUAGgAaQBzACAAUABLAEkAIABp
    AHMAIABpAG4AdABlAG4AZABlAGQAIABmAG8AcgAgAGkAbgB0AGUAcgBuAGEAbAAg
    AHUAcwBlACAAbwBuAGwAeQAuMA0GCSqGSIb3DQEBCwUAA4ICAQBiBuc9JLpv0+nx
    eY5Np7X0HPODG4AdPepVpwh/JUh07G8eClq6ZFoejjiIGpLvMN+Lhfg8Q+hoh7Yb
    z2Gf96TpyAsjx4lmqIgDNfBdf7G0wDf+irP6pifCPBzu2T5519WztvaiZfQoPEz+
    CXm3/yiSKBQUx705fPctx91TjkQEbiBFU3hN9bmw5VkM+2HN7eDJUIUVNXXaTec0
    6M1RhLB2vLVinACpamylLIzShLZpDyk1VI2tniyia+sJulDdpu6kY3LuMr7s97Gj
    UqFHn3PO8lXwYqueJ5xeOjMIKzaliw5n58mDYzpt1uu0u9i0w/8nJpGl4iYwcgBn
    ZPmKet3KG+9LIh/JUdR2KMFv706E4Z24B/QCjbRFqjzS4BDXKmcZV84/HwA48hwa
    yUTWsWZXIibEmvyQcZo9+943o3jkiFYDZZfmQ2a2bzvcHsrNa4ptJYWaBEm2NQWa
    F6pPdUr9uerqyOjRHPkPyd711P7gYC6MWlEKi9JME6lbvanFOwwwh+4nhNnk1iw8
    335Q2U+S8WCzPo7Mzn2DGfa6bdO6sOChXgM//QbaL9GH0LYO8O6XWfS0HSztnBFB
    etCUFffhDdzPkIxfmd7ylGgZSbls2+KFjIgF2M9gKkglmzf5qjNhA1jjHiaUyRTZ
    tRq4ImVO9Ddg1VngqJRZvro+zlH3pQ==
    -----END CERTIFICATE-----
    -----BEGIN CERTIFICATE-----
    MIIGhTCCBG2gAwIBAgITJAAAAAgZo51IZLn3FgAAAAAACDANBgkqhkiG9w0BAQsF
    ADAVMRMwEQYDVQQDEwpFR0FEUm9vdENBMB4XDTE5MDUwMjEwNTgzNVoXDTI5MDUw
    MjExMDgzNVowRzESMBAGCgmSJomT8ixkARkWAnNlMRgwFgYKCZImiZPyLGQBGRYI
    ZXJpY3Nzb24xFzAVBgNVBAMTDkVHQURJc3N1aW5nQ0EzMIICIjANBgkqhkiG9w0B
    AQEFAAOCAg8AMIICCgKCAgEAorS/FxfmNVug9Q963xTydgf5JD/XHEQ0HAypY0Mw
    omgZA1Sj1cRFjFzqVbZlQB/d0RUeN8K9+wzpXl2sDiDTYFKc4v3sesmVrT+VHOtf
    2G1Wuw+7OjMURFhoGNz56vDEL10KH86ViPF0Rx3R5/myKYgn/AX6rdVPSsBPyhAe
    YDdsNX3yWrvxr6x3P5Ze8L5cfgDmw1NR3sR3j9mJSKxEpJHo/6z+wh1xOgV7z8Kj
    Tzdl0+103ZvPw8wpnX3JGwOy5O/lIXMFctMEvZoD/eIerPtYEdjk8HrGbWWu66VK
    EoXopl0/3MbPypVdizPcRBq7ldaCDDdLMi2LjFvZbD0UwHHjR/piIE/YsdPLxi1o
    KSO2vPJHSPjpQ0JtP0gcAGR1wSFQCiOzklupMzZ1PMSySbT04woRnUDdTu9BMzIi
    OV5scI+KtJ1JmPqHq3nCS2nkA0grSNbsbB0bz/mrJLX+wH3CXNj0r0gBIDKlaPQb
    8UzrahG3uuIGk4/x8gnU/wh5WYeU89o+3neIgXySK5chnjfevWBwYVF1vddYltpf
    DFZYuFwT+zefeMEiPnseW6JSnRvNljz1XsBlPC++UydVJDGkp+WzeCR46J6iCVeK
    kWKoLv+BtNIbue7SJw0GdGWBJ0DzKdPBmp+Ya5YPDE1g8SqrfdlO61ykJQ1L6EGf
    Sb0CAwEAAaOCAZowggGWMBAGCSsGAQQBgjcVAQQDAgEAMB0GA1UdDgQWBBSBekIQ
    iZ64URB+VptBwt+veMU9JDB5BgNVHSAEcjBwMG4GBFUdIAAwZjBkBggrBgEFBQcC
    AjBYHlYAVABoAGkAcwAgAFAASwBJACAAaQBzACAAaQBuAHQAZQBuAGQAZQBkACAA
    ZgBvAHIAIABpAG4AdABlAHIAbgBhAGwAIAB1AHMAZQAgAG8AbgBsAHkALjAZBgkr
    BgEEAYI3FAIEDB4KAFMAdQBiAEMAQTALBgNVHQ8EBAMCAYYwEgYDVR0TAQH/BAgw
    BgEB/wIBADAfBgNVHSMEGDAWgBRWRUJaFKi5LET+mzXE2+4vOYJN0DA/BgNVHR8E
    ODA2MDSgMqAwhi5odHRwOi8vcGtpLmVyaWNzc29uLnNlL0NlcnREYXRhL0VHQURS
    b290Q0EuY3JsMEoGCCsGAQUFBwEBBD4wPDA6BggrBgEFBQcwAoYuaHR0cDovL3Br
    aS5lcmljc3Nvbi5zZS9DZXJ0RGF0YS9FR0FEUm9vdENBLmNydDANBgkqhkiG9w0B
    AQsFAAOCAgEAk6hklv9NPua9UImj08ILq43l9SgFhg5+y1pRsrUwdTmFANkL0dxi
    TOF93QwFTfwOs1xJr2nzvCsoJ2Rvc04VQlONwiTqn1kMs9vJr2fuQg9hf2O9l0ss
    AftlHq+UxbeIhloGTyJgleJUc2/+pm4UJn8fhZvNZywL8ok4xr5HQRH5xQz21X4i
    VF9RJlvZbsdWLX1iJMs8+oZJQmhRxoHsPylg+24xLuKFuva7BevDub4HpF6utXeE
    qRMN8Yd1HPg55abf8wEqt1VqNp2erZfLETdf59aXdznqeI+ZJl8gQZwBsOlSANct
    n0nj306BlYm6jthXb7T/Bgau48qyrH/vEnwawZ+RH2q1UvGiAMY1/L5PAP4LGubP
    q5VHsibvoQz+jld2bWM4X8y7Z93s33/elZo26pNuYWiE67IVmZntoHJZmq0RfI7V
    cG27eExeNXYc7T0HheK32CguyDsDUURHOMfMzUJBzDnZ8zQWWeOsKCut9xcpxpPW
    7XQB+iH59lFgRF0WW3H4Z3jh7Kvfbr6XsbzEx/onzLaEVrXBf1xKlXgV5rZW69w1
    It5HdRmqOsfW32Bdz9JehI+Z/Iql9UFDsM1lS9dWfMj4Kv3ALpmG5uS3SjU5y1+e
    7EaQhOp85z15UYt9yoS7KqaNZ07bZb2uzBs32lN/Bn1vwPoLA60kI48=
    -----END CERTIFICATE-----
    -----BEGIN CERTIFICATE-----
    MIIDfTCCAmWgAwIBAgIJAMxZMgsm5U6kMA0GCSqGSIb3DQEBCwUAMFUxCzAJBgNV
    BAYTAlNFMQswCQYDVQQIDAJTVDELMAkGA1UEBwwCU1QxETAPBgNVBAoMCEVyaWNz
    c29uMRkwFwYDVQQDDBBDRUUgVGVzdCBSb290IENBMB4XDTIwMTAwMjAzMzgyOFoX
    DTMwMDkzMDAzMzgyOFowVTELMAkGA1UEBhMCU0UxCzAJBgNVBAgMAlNUMQswCQYD
    VQQHDAJTVDERMA8GA1UECgwIRXJpY3Nzb24xGTAXBgNVBAMMEENFRSBUZXN0IFJv
    b3QgQ0EwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC1uxOXgIUZn65P
    ilGVm4s5FvIQMylXf3+UH0dseaYD+/cbb8GalypA08t071N7fAx/gra8V+WZ4oF6
    H6PQoFry4axPi7qNI2NrHfaLOqjTwGF1qAjWgSkKaTc5efIL/4daAS3S3O0qzHU+
    bon88nvjL4LytHfHr20Vv//0bBxTQ/QbPWSYVHSwdk0uiQ5GHCjxgy6ykIKLEQ5m
    YrGaroHzv+wJxIb3PfPaOMv1jpWcn7sABVdqFuiKB7CKcnpPxrB5RBbJZoZrUOIZ
    KRW+PQniwFOPEvTZ/rJPHcwPg3qR/xTPXx7wQKnSZindsV2ecYwqz9DzppW43YH2
    oTbTgAWNAgMBAAGjUDBOMB0GA1UdDgQWBBQE3xlNdp+CS7XzvEWD9Zi6sxmW8zAf
    BgNVHSMEGDAWgBQE3xlNdp+CS7XzvEWD9Zi6sxmW8zAMBgNVHRMEBTADAQH/MA0G
    CSqGSIb3DQEBCwUAA4IBAQBfP5L/qVTG+SrJGpTEYPmebkXM3KW6pj9oAvpWu7y9
    QikA5gB/IQa7f1bHzqqHurVHqbJGmAxcFK1iIkbxjmeW/avDwdYz7Zs61XU42SDb
    qHji6LPMfwFpJg0Yxi2XPgHBrRwgQIN5ZExweANu+GSiMVd6RbYr7L+wrDUxCrLc
    jUV4sLy7On10soLwKk+yHzleAUDWU7t+9CCQC1Sp9HF7sDnMgl7DSUkv4JF1jkc8
    o8kXZhYMybI03T5HGklESGIz4h2ppCVsUX7BXZkQL8iSGGz1sXodnkmI4QncGao9
    phfRLN8/VU1LPbJptn3HGU6P1yZPdeTGWibDIIFgu2ot
    -----END CERTIFICATE-----
    # evnfm self-singed CA certificate
    -----BEGIN CERTIFICATE-----
    MIIGCTCCA/GgAwIBAgIBADANBgkqhkiG9w0BAQsFADCBnjELMAkGA1UEBhMCU0Ux
    EjAQBgNVBAgMCVN0b2NraG9sbTESMBAGA1UEBwwJU3RvY2tob2xtMREwDwYDVQQK
    DAhFcmljc3NvbjEVMBMGA1UECwwMUEMgU29sdXRpb25zMRgwFgYDVQQDDA9UZWFt
    Qmx1ZXNSb290Q0ExIzAhBgkqhkiG9w0BCQEWFGtlbi5zaGlAZXJpY3Nzb24uY29t
    MB4XDTIwMTEwMjA5MzMxNloXDTQwMTAyODA5MzMxNlowgZ4xCzAJBgNVBAYTAlNF
    MRIwEAYDVQQIDAlTdG9ja2hvbG0xEjAQBgNVBAcMCVN0b2NraG9sbTERMA8GA1UE
    CgwIRXJpY3Nzb24xFTATBgNVBAsMDFBDIFNvbHV0aW9uczEYMBYGA1UEAwwPVGVh
    bUJsdWVzUm9vdENBMSMwIQYJKoZIhvcNAQkBFhRrZW4uc2hpQGVyaWNzc29uLmNv
    bTCCAiIwDQYJKoZIhvcNAQEBBQADggIPADCCAgoCggIBALpFSt2RPftYwPHaaX0O
    li/g52VnHmyACmG1egnPA4efRptfFqsm9lHH2byigSech+zfLXCarVErdu1/yvRG
    zYaLgH/76XtOVXpGYa3aXBksBbkTnIRmgtq11iIdOKXUrVbVt4HZ20EJxrFrMs9n
    mxy7dvhWM1KrSVSUqN840DSWJxeFWWgEZ7vTgRhnuAD2FUqsZ6CRvt2iL31ZNIco
    dqOUQF9chZLWgprEDgRmJD4oLjVoWe0kS/zRR2G3GB9J28xs9ZjSp38CtTgqBzyv
    gWua4Im5KyFIJUeH4a9NRYZWry6I9sxAzIYVt7ki3TAP+K2YsGg9dD1GwKDR+5Zy
    7EVuri9hqR5YFrvvdNAjWrJvymQXaDdmXUGa7Og8p9IzM+lNL86dDf3BsyeqHJrq
    m31OMHM3MCVfc0zUu96LnLj2wqTdKa7MaWyfA7KO38wIACBvO/SNCCzCXpADJRED
    A3n219y6QxmM+DH35XVBTvJkM5UxPHoa8rhZsuLhobIyNU/Kuk6JAm/lueYzOG9k
    lLmaaSasdlNJ/Pqf4MBOB1UKPVsJsravFaQ7BmOLp3R0XyhoNrnmd/OOxU6r1TH1
    wh5vx2CAOO4tujvnihgeADU8yQdwDKBkOtjjV0TdY0MFxecLowtmEnrKfIO9kSS3
    tpnAgdBgfq7eOYvsrKw31AqxAgMBAAGjUDBOMB0GA1UdDgQWBBTqkIEarX28jATB
    MBsv/Vse5jCebDAfBgNVHSMEGDAWgBTqkIEarX28jATBMBsv/Vse5jCebDAMBgNV
    HRMEBTADAQH/MA0GCSqGSIb3DQEBCwUAA4ICAQB73tG3G1mZt93j5MoRXimsB6sO
    q47A/lZiyJKqJiLIeSq1V8GOPwqfQyNAe40inhLWHYky5rPfhhXw+FlyW4zotv7W
    ZygTjtCwa7EbawUMOoG9YcMhK9NZx/EoPT0cs4BK6UvajpH28Kl5+fyvSLN5ZY7K
    arBIMUWNVs7m3O9e5doLx6e98soj2U5PkGq1AB2xgwX7F0spIj3Yg3WS4C5z5KkF
    b1cviVgHuFnxJNGu5nY+h08+i5cZNu/Uc1M9pkYthlfnhpyPlONxD9rTpDm5LEkU
    3af9zyqwJuuunWDJMfKKZGPB5BCgfM6hBw4D3iLWTWxrHfjNghNVqCh6K+L+GdfD
    hzT/LVSHW/bOjHh+wAVGFcFxxXedXxq/prj1ZwflPI7XvxuCwj1EVA630FIBSC6/
    xWq8mHoECXXp839Gccd3tmeauELrchkty6OaBpwHg/dB44GEByJz/T+lbLIOZLXd
    K+kpgaN4TmA5wtlQPMq0HQLvEax+cCUYtE78QSe+86mV/2Q1EeJNEesT7p5C2U4c
    aQZbPQ6YgvRZtvPD/3CrQS9CD0DJwaCrj2dEISb4lEj/fz5wlLETyS7X/0KYUMKR
    UmqyKwz2Zs9jM7By0HxM1i+0f/ovMDuKuQ6IQTROEu0TZZVH6KRsDuujv+/VJ2Nb
    szlrRw3la1H71eU9UQ==
    -----END CERTIFICATE-----
  ca_cert: |
    -----BEGIN CERTIFICATE-----
    MIIDAzCCAeugAwIBAgIJAMSmaEvd/VMQMA0GCSqGSIb3DQEBCwUAMBgxFjAUBgNV
    BAMMDUt1YmVybmV0ZXMtY2EwHhcNMjAwNzEwMDMwNDQyWhcNNDcxMTI2MDMwNDQy
    WjAYMRYwFAYDVQQDDA1LdWJlcm5ldGVzLWNhMIIBIjANBgkqhkiG9w0BAQEFAAOC
    AQ8AMIIBCgKCAQEA2wyPymF3Nk/HD77qdg4zMz0m4VDcRCDCTwkvHhVwJM6LoX0z
    rlrorVRL6KyAkJRvxdjqJ2ioGwLduI911xojd+70eU6ws0H8mrL+M3jkisRm9j/H
    CjWyMcPCeXPfGq2myBs43w+b/vHIGSHw30bPqR2ZCU3oMIBTrYtZObTP6WrXkPap
    5Vp+r+JUux6QYILF7Jr+o9YHdfTMYzxD2Y3ryyetcmj6G6poRAJn5jQksUDzrWaa
    G8sYJD6+0yyYXajgEP6MN71hsDieNiejFVdCFPx7aRQmKZeYiGWxttXkOTaznXBn
    xars4eQm4zvhz9qw2YBFgr+3+LQgMrEP72dROwIDAQABo1AwTjAdBgNVHQ4EFgQU
    Mc5NugDUN7qggOCf40HMyQlyX5gwHwYDVR0jBBgwFoAUMc5NugDUN7qggOCf40HM
    yQlyX5gwDAYDVR0TBAUwAwEB/zANBgkqhkiG9w0BAQsFAAOCAQEAFllDan/0tA5X
    //OHz0qUo+PPz9xctye+PRe/MUIFQqUQsg4XAABlxsp3N4xC2VsD/ncZAcfcy9aY
    rf7s53+b2Fy0ENJLKjvEZBWo+DDQL786s/HoUwV34LcHDRIfo/W4JjwPE9Aj0SP+
    XicqykZR5nPtWSxalDNylydFTqHSwij+JetWtxXG6/hQUfVRIUS4uKO40sEB4Rph
    nICfPQxQqb7L4FrWpTEp3fW/Vq1hvMlnVj9qorImsvvSvL/s7a6h6DpJiJU8+JdN
    ZchFa7zTBL3VCmx+puUwYDAWiA0sszZWZcxZZWTqBp2/uo872CuevZ3jBx7de9i/
    aw99cpwQjw==
    -----END CERTIFICATE-----
  ca_key: |
    -----BEGIN RSA PRIVATE KEY-----
    MIIEpAIBAAKCAQEA2wyPymF3Nk/HD77qdg4zMz0m4VDcRCDCTwkvHhVwJM6LoX0z
    rlrorVRL6KyAkJRvxdjqJ2ioGwLduI911xojd+70eU6ws0H8mrL+M3jkisRm9j/H
    CjWyMcPCeXPfGq2myBs43w+b/vHIGSHw30bPqR2ZCU3oMIBTrYtZObTP6WrXkPap
    5Vp+r+JUux6QYILF7Jr+o9YHdfTMYzxD2Y3ryyetcmj6G6poRAJn5jQksUDzrWaa
    G8sYJD6+0yyYXajgEP6MN71hsDieNiejFVdCFPx7aRQmKZeYiGWxttXkOTaznXBn
    xars4eQm4zvhz9qw2YBFgr+3+LQgMrEP72dROwIDAQABAoIBAQCKvDYGFB0RBQ4q
    5txQ0UWUWlLZugEIFUd8D3EMOL/CUB8XtNiawXFE9nLtdvQmnhz8zhnfw+VU1kff
    sN0N07xLJckpW7GGl3CJ+nwN1a/KRAKCTHqf+MpXwojVq5HOr9VGQBeRD63ZlwEJ
    CfopMAwuLFTVE8bPkTduXyev6NkWGC1gVp0PH6/TSkJ3pKOOJuALJsinoVhLCybt
    jb96nBeKXQERFZcSjKMTaipHwDGpXDVMIqFBICKRkNhBzqDs7OTdqCNUPpcmlZ1g
    Vb77g2rXOm45pFgQ5qpogPWLNl69NvUbP7t2MNurYW87jLZv1tORMNwDJLhvIxMd
    FMBsB23BAoGBAO1DW0P34e0FPHvhODn1XQEoOHpIWWfK2tncw64f62Kfc+7s30fd
    d3J1xbwvNJDJ5bLtLN/ocxp/s7x+kQW1lDEmsZkjPAqLy/pCC3P73kePxL35rNa7
    rahJbgedrZUI4vDVjGDfFGFSbnnvQiHkRcBxZLSUawnYRkaQ3nCI76Q5AoGBAOxY
    +ty6M8VhkAcrai2+yc9pe7scGO7U8euppW2vATsATekD2zRs5quyYIF30/os/PkC
    MYDxcRT+pClEmpG4y7kjNTxSoxFkorFJuF+kZh3B5eBLGSU2HkSGC6Jsw7F59N2u
    n6AKNaFRW84taFUx1YEFksONvlHJt5/BZq6w2SkTAoGAVJhqhw5wAHmYejbwPEIO
    2iXEFV2MeyRp6bn8Dy6UV8KwrGTKq638M9RoH1PZczJ5ctV75Y3U1ILpy/B4tsdq
    QiggtJBKjRwRK3a27LDGLU/Gf1HxXVLndRRRZefDh1r2x5XsinGfq5+fglxbgQgK
    ErabiINOsuDpFan7lbZNc4kCgYBAUocTg2mLkl3MVbhz8rShyiduaNswRKwCYw0u
    qK5BDHgnrnD995VfrRAurBn4wD2o1zv5x7vq5tJumMkoV466OCbI4ASZOzY74cBX
    5zoTZy3UuRuC0ROzund4IPmxV2uY2Wl/+MdXu/isSBdY+FMO5iFnLzBYuflLdSso
    5+ByGQKBgQCDK4PcuQ3HwfhY5tuKBLnCT94sIZ/kjiPE3GYpWaNMRvEAGGf25C3Y
    gXRgyKlwCacrX2J1ycnBubvChG5RGD7b3zBTyXkb7nhsmKKXQaNRoIoqQhMx8kkn
    3Io5i+/TVONAovqjCA0IhVSnXGCdDxwp7gm87Hi7yoWbxurJA6zWlw==
    -----END RSA PRIVATE KEY-----

  public_key: >
    ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDB+iokdoFkfbZL4x4qxOnCzTPhVrYgFGGp7u1tNthrTupSD3jDv3G1wdNY+LYDhWFVo5d3cCiCOSrNY7ycFU3k5t3g04ODgmYuoPKwg3fD9ienWohbrtd1oRZh5pxPBwn3SixSEWeah5eIRbRn1myjpGOa8H5VYF4+yih2gWmDBnXjX1H0yuNIkQVutTEMb2HxPYaDtXM1G0f5PPFUBSOyeFuoanmBW/7F6MKyPwC4wZMWYhb//vr5UmjAT8ZzHYGvX888vFPukN5da9GUgHinENg4HuIzgd/NFk6la9U13fmyrdmcRZGUStAKweQZ3v+SM0nSNXXh0X8X/41jnLhZUFtN7/cn9H4NPKYU621z/cjCFXIit36Hg7Kf/6r1iSXhUHq0v8G8a0mg6AbBETCv47y/EY8VMByY1/mh4G/HsnVf7uvuLWCv0FMXHmGcgcqGaesDr73o++HI1SSf5vXt2tM8hb5C8Q9FHFNugoW/+feMnehec27FciC3q/Y30fE= ceeinfra@controlhost2.cee.tld

  ################################### Optional variables #########################
  # Custom root password for console access
  # must be sha-256 or sha-512 password hash type
  # update the below value to set the root password
  console_password_hash: '$6$hOsTsRex8Tperl39$OxxzVtpng37ykOP0W48kGDlbfHe8t/V1oB5CsceVPOTaRzQFOc6qbdhDYykwXVih7iMRfuomYd/c4ZaFHBmnd/'  
#  console_password_hash: '$6$qMG6m8Uc.p2p8cUP$6Jv7IF7zWCfTil4KxvVHtDhKY3LBVyD6iv9QhsP8LKHYHx6IxQKlPn7mOT/BhLIUVF2RETRX1DzR1MAgXirUY1'
